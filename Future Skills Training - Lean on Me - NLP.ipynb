{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Future Skills Training - Lean on Me - NLP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrVTIjFKOsr1jVFqu8QL9j"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6I1plhAZ7osB","colab_type":"text"},"source":["*A simple solution that works is better than a perfect one that doesn't*\n","\n","Please focus on fast prototyping and building a minimal viable end-to-end product. If you have to skip a few steps that's fine, it's better to come back to improve the logic at the end when you have time. Than not having time to get to the end."]},{"cell_type":"markdown","metadata":{"id":"5-nQitpV7LUC","colab_type":"text"},"source":["• Please clone this notebook if you want to experiment or try new things, keep this version as the ground truth for everyone (since we won't be using version control)\n","\n","• Keep your code clean and tidy (if someone else reads my code would they understand what's going on?)\n"]},{"cell_type":"markdown","metadata":{"id":"Hj-G6dry9xWz","colab_type":"text"},"source":["**Useful Resources**\n","*   Basic end-to-end sentiment analysis project with NLTK: https://towardsdatascience.com/basic-binary-sentiment-analysis-using-nltk-c94ba17ae386 (copy any code you want to get you head-started)\n","*   Here's another example with Vader: https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f\n","* For those willing to dig deeper this is a good starting point branching out to many useful and interesting resources: https://medium.com/fintechexplained/end-to-end-guide-for-nlp-project-55e6765f63b5\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g3kjLXN89nfe","colab_type":"text"},"source":["**Import Libraries**"]},{"cell_type":"code","metadata":{"id":"dgWfZ2fS6bUU","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import nltk \n","from sklearn.pipeline import Pipeline\n","from nltk.tokenize import word_tokenize\n","from nltk.classify.scikitlearn import SklearnClassifier\n","import re\n","# more useful stuff as we go"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxIAdASunAYF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"f4c0f969-7b97-4ba3-fb79-4745681cd349","executionInfo":{"status":"ok","timestamp":1583075306587,"user_tz":0,"elapsed":17512,"user":{"displayName":"Achilleas Athanasiou Fragkoulis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvkZvutbpq0EJn6k7QD2OlAk56glb-VtCI6HCx=s64","userId":"11611346081717613641"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eJBPSKKNnDD-","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"FST_full_IDs.csv\", na_values = [''])#.dropna(subset=['description'],inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e52nohFenl_D","colab_type":"code","colab":{}},"source":["# def duration (row):\n","#    if row['duration'] < 1.5 :\n","#       return 1\n","#    elif row['duration'] < 2.5:\n","#       return 2\n","#    elif row['duration'] < 3.5:\n","#       return 3\n","#    elif row['duration'] < 4.5:\n","#       return 4\n","#    elif row['duration'] < 5.5:\n","#       return 5\n","#    elif row['duration'] < 6.5:\n","#       return 6\n","#    else:\n","#       return 7\n","\n","data['rounded_duration'] = data['duration'].round(0).astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bY_5hB7E-tro","colab_type":"text"},"source":["**Pipeline**"]},{"cell_type":"code","metadata":{"id":"5VRvvuB5-tNa","colab_type":"code","colab":{}},"source":["# ignore for now let's get back to this once we have an end to end working product\n","# we will put here all the steps so we can execute the process all the way in 1 place (taking a functional programming approach for similcity)\n","# this will look like\n","\n","\n","\n","# import data\n","# cleaning \n","# data engineering\n","# train\n","# test\n","# experiment / tune\n","# validation (we can think about this at the end only if we have time)\n","# predictions / output (we can think / play with a microservicing structure and API or containerization)\n","\n","text_clf = Pipeline([\n","                    ('vect', CountVectorizer()),\n","                    ('tfidf', TfidfTransformer()),\n","                    ('clf', MultinomialNB()),\n","                    ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8UUl0hw9tWr","colab_type":"text"},"source":["**Data Import**"]},{"cell_type":"code","metadata":{"id":"2tVqeTPe-JeT","colab_type":"code","colab":{}},"source":["raw_data = pd.read_csv(\"data.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyrIpDOV-ZXV","colab_type":"text"},"source":["**Data Cleaning/Processing**"]},{"cell_type":"code","metadata":{"id":"z20Q_ns0-YXe","colab_type":"code","colab":{}},"source":["# which data points are absolutely necessary? if they're missing probably best to drop the row\n","# let's think about data points that are not mandatory do we fill, impute, drop?\n","# step for later - future proof this so we don't pass on empty data to fitting and break a model that expects input"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1iBkW7M-ms-","colab_type":"text"},"source":["**Data Engineering**"]},{"cell_type":"code","metadata":{"id":"746iu9QV-YuY","colab_type":"code","colab":{}},"source":["# skip this step for now let's iterate after we've done a first pass\n","\n","# Tokenization\n","# Stop word filtering\n","# Negation Handling (not sure if necessary or useful in our case)\n","# Stemming or Lemmatization\n","# let's think later about upper/lower case or if we want to preserve for emphasis handling (depends on model)\n","# n-grams\n","# encoding (?)\n","# you can read about vectorization and embeddings for fun but will leave out of scope for this project"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnOzYI9IA7Ab","colab_type":"text"},"source":["**Model Training & Testing**"]},{"cell_type":"code","metadata":{"id":"wv1H4y-b6tEV","colab_type":"code","colab":{}},"source":["# Let's iteratively tackle the below\n","# Stats models (BoW) \n","# NLTK, Vader (maybe we can find something off the shelf that works better in this domain? \n","  # there are some lexicon based models that focus on emotion detection rather than positive/negative sentiment)\n","# Neural Nets w. Embeddings (BERT and its derivatives) - if there's time we can play around (this is state of the art at the moment)\n","# Apart from identifying sentiment we can play around with the idea of also identifying themes being discussed, annotating the corpus, \n","  #  capturing and or producing meta-data and more - open to ideas & suggestions here\n","\n","# For testing (and validation if we go there) we will need an additional corpus, as I assume our data is not labeled so we can't go \n","  # down a supervised route, anyway we wouldn't have enough data. All we care is getting a sense of how well our model transfers into our domain"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQOXr9vhcTeT","colab_type":"text"},"source":["**Predictions**"]},{"cell_type":"code","metadata":{"id":"f8kYLIZ2cTm4","colab_type":"code","colab":{}},"source":["# ask the model to return sentiment for new input data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJUtK8RidZRs","colab_type":"text"},"source":["**Serving the model**"]},{"cell_type":"code","metadata":{"id":"12-VIe72dbfA","colab_type":"code","colab":{}},"source":["# Let's worry about this at the end if of interest to play with packaging, deployment, web-service and API calls to the model\n","# For those interested in putting something unique on their CV ;) \n","# A question every employer will ask \"have you deployed a model in production?\""],"execution_count":0,"outputs":[]}]}